





# import libraries first
import numpy as np
import matplotlib.pyplot as plt

from IPython.display import Audio
from scipy import signal
from scipy.io import wavfile
from skimage.io import imread
from sklearn.cluster import KMeans

%matplotlib inline


x = [0, 1, 0, 2, 0, 2, 0, 1, 0] # test signal

full_fft = np.fft.fft(x)
real_fft = np.fft.rfft(x)

omega_full = np.linspace(0, 2*np.pi, len(full_fft)) # left limit, right limit, # pts
omega_real = np.linspace(0, np.pi, len(real_fft))

plt.figure(figsize=(15, 6))
plt.subplot(121)
plt.title('Full FFT')
plt.xlabel('$\omega$')
plt.ylabel('Magnitude Response')
plt.plot(omega_full, np.absolute(full_fft))

plt.subplot(122)
plt.title('Real FFT')
plt.xlabel('$\omega$')
plt.ylabel('Magnitude Response')
plt.plot(omega_real,np.absolute(real_fft))





x = [0, 1, 0, 2, 0, 2, 0, 1, 0]

full_fft = np.fft.fft(x, 512)
centered_fft = np.fft.fftshift(full_fft) # shifts central frequency to middle of array
real_fft = np.fft.rfft(x, 512)

omega_full = np.linspace(-np.pi, np.pi, len(centered_fft)) # new frequency axis
omega_real = np.linspace(0, np.pi, len(real_fft))

plt.figure(figsize=(15, 6))
plt.subplot(121)
plt.title('Full FFT')
plt.xlabel('$\omega$')
plt.ylabel('Real Part')
plt.plot(omega_full, np.absolute(centered_fft))

plt.subplot(122)
plt.title('Real FFT')
plt.xlabel('$\omega$')
plt.ylabel('Real Part')
plt.plot(omega_real, np.absolute(real_fft))





b = [np.sin((np.pi/2)*n)/(0.5*np.pi*n) if n != 0 else 1 for n in range(-100, 101)] # numerator coefficients
a = [1,0] #denominator coefficients
w, h = signal.freqz(b, a) # w = omega/digital frequencies, h = frequency response
plt.figure(figsize=(10, 6))
plt.title('Toy Frequency Response')
plt.plot(w, 20*np.log10(np.absolute(h))) # plot magnitude of frequency response with db-scaling on y-axis
plt.xlabel('$\omega$')
plt.ylabel('Magnitude Response (dB)')





# Function to implement for part 1.a:
"""
Inputs:
x - input signal (list or np.array)
w - frequencies we want to compute the DTFT for (list or np.array)
Output:
dtft - value of the DTFT for signal x at each frequency specified in w (list or np.array)
"""
def myDTFT(x, w):
    dtft = [] # create empty list to append resulting computation
    # Iterate over each frequency in w
    
    # Compute summation for current frequency according to our DTFT definition, "1j" gives you the imaginary number
    
    # Append result for current frequency
    
    return dtft

# Code for part 1.b:
x = np.array([np.cos(0.5*np.pi*n) for n in range(50)])
# endpoint argument makes sure our definition aligns with the np.fft.fft result
w = np.linspace(-np.pi, np.pi, 50, endpoint=False)









# Code for 2.a:
# Remember to plot magnitude and phase of signals side-by-side with plt.subplot(nrows,ncols,plot number)


# Code for 2.b:


# Code for 2.c:
# Remember to plot magnitude response with dB-scaling on y-axis.

# Code for 2.d:







# Code for part 3.a:


# Code for part 3.b:


# Code for part 3.c:







fs, audio = wavfile.read('audiofile.wav') # load the data
print(audio.shape) # one channel


Audio(data=audio, rate=fs) # give it a listen for reference


# Code for 4.a


# Code for 4.b




# Make sure to typecast audio before listening to it as follows:
audio_result1 = audio_result1.astype(np.int16)
audio_result2 = audio_result2.astype(np.int16)


# Listen to result 1 here!
Audio(data=audio_result1, rate=fs)


# List to result 2 here!
Audio(data=audio_result2, rate=fs)











Fs = 44100 # sampling rate for audio clip in Hz
t1 = 5 # make clips 5 seconds
t = np.linspace(0, t1, t1*Fs) # make sure to specify the number of points to match desired sampling frequency!!!
f0 = 0 # start frequency (Hz)
f1 = 22050 # end frequency (Hz)

"""
instantanous frequency, f(t) = f0 + (f1-f0)*(t/t1)
"""

chirp_original = signal.chirp(t, f0=f0, t1=t1, f1=f1)


# BE CAREFUL WITH YOUR VOLUME! CHIRP SEQUENCES CAN BE LOUD!

Audio(data=chirp_original, rate=Fs) # give it a listen





# Code for 5.a here:


# Code for 5.b here:




# Code cell to listen to different chirps you generate
Audio(data=current_chirp, rate=current_fs) # Remember to use correct sampling frequency!








# Part 6.a
# Fill in the below function!
"""
image - image we want to color quantize
k - number of quantization levels (# of crayons)
For example, k = 4 means we will have levels at 0, 85, 170, and 255.

returns: q_image = color quantized image
"""
def uniform_quantizer(image, k):
    # create quantization levels
    levels = np.linspace(0, 255, k) # k evenly spaced colors from 0 (black) to 255 (white)
    # create a new/blank version of the image and compute quantization level spacing
    q_image = np.zeros(image.shape)
    spacing = 255/(k-1)
    # go through each pixel in the original image, assign quantized value to new/blank image
    # remember we choose the quantization level closest to the original value
    
    # return your quantized image
    return q_image


# Part 6.b/6.c
# Function has been provided for you!
"""
image - image we want to color quantize
k - number of quantization levels

returns: q_image = color quantized image
"""
def lm_quantizer(image, k):
    im_shape = image.shape
    n_rows = im_shape[0]
    n_cols = im_shape[1]
    # create k-means object
    kmeans = KMeans(n_clusters=k)
    # reshape pixel value to be like data points
    if len(im_shape) == 2:
        pixel_vals = np.array([[image[row, col]] for row in range(n_rows) for col in range(n_cols)])
    else:
        pixel_vals = np.array([image[row, col] for row in range(n_rows) for col in range(n_cols)])
    # fit the k-means model to pixel data and get color labels
    color_labels = kmeans.fit_predict(pixel_vals)
    # create blank version of the image
    q_image = np.zeros(im_shape).astype(np.uint8)
    # assign appropriate color to each pixel based on color labels
    colors = kmeans.cluster_centers_.astype(np.uint8)
    for i,label in enumerate(color_labels):
        q_image[int(i/n_cols), i % n_cols] = colors[label]
    return q_image


# Code to test 6.a


# Code to test 6.b


# Code to test 6.c








